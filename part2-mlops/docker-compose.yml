version: '3.8'

services:
  mlflow:
    image: mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000

  server:
    build:
      context: ../..
      dockerfile: part2-mlops/docker/Dockerfile.server
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    ports:
      - "5050:5050"

  client01:
    build:
      context: ../..
      dockerfile: part2-mlops/docker/Dockerfile.client
    environment:
      - CLIENT_ID=01
      - SERVER_ADDRESS=server:5050
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - server
      - mlflow

  client02:
    build:
      context: ../..
      dockerfile: part2-mlops/docker/Dockerfile.client
    environment:
      - CLIENT_ID=02
      - SERVER_ADDRESS=server:5050
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - server
      - mlflow
  inference:
    build:
      context: ../..
      dockerfile: part2-mlops/docker/Dockerfile.inference
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    ports:
      - "8080:8080"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
